{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cbbbef98-98a2-44bb-b89f-dd5aa759f648",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"논문 라이팅\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2024-05-16\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a3afe-5fa4-4947-86c9-50beb4d20133",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac36b5-1b9c-4c82-af33-c5d6a15c6d89",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a3539-02e8-4c50-81f5-0a176dcd6ef6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff77f45-9576-4b3d-ba70-0659d6263894",
   "metadata": {},
   "source": [
    "In recent years, the field of the spatio temporal dataset has emerged, enabling the simultaneous consideration of both the time and space dimensions. The examples include consumer demand data\\citep{rozemberczki2021pytorch}, wind turbine records\\citep{rozemberczki2021pytorch}, neuroscience data including brain networks\\citep{atluri2016brain}, traffic data like taxi GPS traces\\citep{castro2013taxi}, and more. \n",
    "\n",
    "- STdataset 가 출현함 \n",
    "\n",
    "Classic time-series statistical methods to analyze those kind of data already exist, but they are limited by certain conditions, such as assumptions about the data. Specifically, these classic methods are hard to account for spatio temporal correlations and are not designed to work with spatio temporal data\\citep{yu2017spatio,rozemberczki2021pytorch}. \n",
    "\n",
    "- 근데 그건 전통적인 시계열로 분석이 어려움 \n",
    "\n",
    "In result, when we analize spatio temporal data to use enough information, it leads to improve accuracy during using appropriate geometric deep learning frameworks.\n",
    "\n",
    "- 그래서 GDL을 써야함\n",
    "    - 접근하는 방법은 크게 전통적인 시계열방법과 GDL이 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f4b05-5828-4c42-8ee5-4e888d7481ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25346e03-84a4-4ebe-ae5d-5d7fdb9cf40a",
   "metadata": {},
   "source": [
    "However, dealing with spatio temporal datasets often presents a common challenge, which is the frequent occurrence of irregularly observed data. For instance, as highlighted by \\citet{ge2019traffic}, traffic sensor data commonly suffers from missing observations due to electronic unit failures, which can significantly impact prediction accuracy. \n",
    "\n",
    "- 그러나 STdataset은 미싱이 있으면 동작X\n",
    "\n",
    "The difficulty in handling irregular data is that many traditional data analysis procedures were designed for datasets with complete observations \\citep{schafer2002missing}. \n",
    "\n",
    "- 이유1. GDL의 대부분 방법은 fully observed 되었다고 가정함.\n",
    "\n",
    "~Second, when dealing with time-series datasets containing missing data, attempting to learn from such data can lead to challenges as it may result in the failure to capture certain time points\\citep{ge2019traffic, tian2018lstm}.~\n",
    "\n",
    "- ~이유2. -> 시계열에서 미싱이 있을 경우 분석에 어려움이 있다는 연구가 있음.~ \n",
    "\n",
    "That's why it's essential to transform incomplete data into complete data before conducting any learning or analysis.\n",
    "\n",
    "- 그래서 complete data를 만들어야함. \n",
    "\n",
    "Therefore, we set the purpose of this paper that finds closely approciate complete data when we approach the irregularly data.\n",
    "\n",
    "- 이 논문의 목적은 컴플릿 데이터에 가까운 값을 찾는 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f52162-41d2-4efb-a42d-8d24ccc44d79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7968e5-1b01-4bd4-a518-e0e07cdbbadb",
   "metadata": {},
   "source": [
    "Table 1: Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8b7c7-300d-40fb-8890-b6859e52c397",
   "metadata": {},
   "source": [
    "|Notations|Definitions or Description|\n",
    "|:--:|:--:|\n",
    "|${\\cal G}$|Input Graph|\n",
    "|$T$| the length of the time interval|\n",
    "|$\\cal{V}$| a set of Verteces|\n",
    "|$V$|a set of an index node|\n",
    "|$N$|the number of Verteces|\n",
    "|$\\cal{E}$|a set of undirected Edges|\n",
    "|$\\textbf{y}$|a graph signal, a function defined on the vertices of the graph $\\cal{G}$\n",
    "|$\\textbf{W}$ | a weighted adjacency matrix|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1550287-36d7-4dd4-ace4-0c814ac3bfd8",
   "metadata": {},
   "source": [
    "To describe the geometric structures of data domain, graphs are well known as generic data representation forms\\citep{shuman2013emerging}, so we interpret data on Graph domain. Table 1 indicates the descriptions of notations we use respectively. \n",
    "\n",
    "-  Shuman 등이 2013년에 발표한 연구에 의하면, 데이터 도메인의 기하학적 구조를 설명할 때 그래프가 일반적인 데이터 표현 형식으로 잘 알려져 있어 데이터를 그래프로 해석함.\n",
    "\n",
    "To simply understand our method, let's consider the following simple example. Here is a sample dataset:\n",
    "\n",
    "- Graph ${\\cal G} = (\\cup_{t \\in {\\cal T}} {\\cal V}_t, \\cup_{t \\in {\\cal T}} {\\cal E}_t, \\textbf{W})$ ,${\\cal T}:=\\{1 \\text{ to } 10,000\\}$\n",
    "- $\\cal{V}$ is a set of Verteces. ${\\cal V} = \\{ v_0, v_1 \\}$, $|{\\cal V}| = 2$, $V = \\{ 0,1\\}$\n",
    "- $\\cal{E}$ is a set of undirected Edges. ${\\cal E} =\\{ ( 0, 1)\\}$\n",
    "- a graph signal $\\textbf{y}$: ${\\cal V}_t \\to \\mathbb{R}^2$\n",
    "    - node 0 $y = \\cos(2t) + \\cos(4t) + \\cos(8t) + \\epsilon$\n",
    "    - node 1 $y = \\cos(2t) + \\cos(4t) + \\epsilon$\n",
    "- ${\\cal Y} = \\{ y_{v,t}:  t \\in {\\cal T}, v \\in V\\}$\n",
    "- Define ${\\cal Y} = ({\\cal O} , {\\cal M})$\n",
    "- A missing data ${\\cal M} = \\{ y_{v,t_v}:  t_v \\in {\\cal M}_v, v \\in V \\}$\n",
    "    - missing rate on node 0 = random missing 60%\n",
    "    - missing rate on node 1 = random missing 60% + block missing $1600$ to $4000$\n",
    "- A observed data ${\\cal O} = \\{ y_{v,t_v}:  t_v \\in {\\cal O}_v, v \\in V \\}$\n",
    "\n",
    "For learning data on example, we used GConvGRU. After updating the graph signal set $\\cal{Y}$ 200 epochs, we achieved meaningful outcomes(animation link)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9e37e-a73a-435d-be31-f685c36b7a2e",
   "metadata": {},
   "source": [
    "In this paper, we expect to contribute as follows:\n",
    "\n",
    "- we can appropriately predict data when we get spatio temporal dataset with higher missing rate. \n",
    "\n",
    "우리는 높은 미싱 비율을 가진 stdata를 만날때마다 적절히 대처 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64aa1b9-7916-40c9-a7b9-060f017d102a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4da57-23c0-4a1d-baab-a72dbf71f2b2",
   "metadata": {},
   "source": [
    "# Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d53a60-3e34-485b-bca6-a20a5c2a6ad2",
   "metadata": {},
   "source": [
    "When observed data is incomplete data, a general approach was approached to handle this problem by using the underlying complete data. \\citet{dempster1977maximum} defined expectation-maximization algorithm as an iterative technique while computing the log-likelihood from incomplete data. Furthermore, the term of self-consistency is introduced by \\citet{flury1996self} who showed the similarity between expectation-maximization algorithm and \\textit{k}-means algorithm.\n",
    " \n",
    "- 불완전한 데이터는 완전한 데이터의 언더라인을 찾는 접근이 일반적임\n",
    "- EM 알고리즘 + self-consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891d2db-be36-423b-a694-b13c58bf8285",
   "metadata": {},
   "source": [
    "In terms of the irregular spatio temporal data, it poses a challenge as neural networks are more adept at handling regular data. It is often mentioned as the simple solution such as imputation algorithms\\cite{beretta2016nearest} or linear predictor\\cite{durbin2012time}.\n",
    "\n",
    "- 비정형 시공간 데이터는 신경망이 처리하기에 더 어려움\n",
    "- 간단한 해결책으로는 대체 또는 선형 예측이 있음\n",
    "\n",
    "Furthermore, to fill missing values, \\citet{bai2020adaptive, yu2017spatio, guo2019attention} employ linear interpolation, while \\citet{cui2020graph} utilize historical data. All of them tried to convert heterogeneous graph into homogeneous graph which has the same types of nodes and edges, while heterogeneous graphs do not\\citep{zhou2020graph}.\n",
    "\n",
    "- 또한, hetero -> homo graph로 바꾸려는 시도들이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0da73c-66ff-4ddf-b564-0a969969f586",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df45c40-2c7d-416e-9249-f5b045e458ac",
   "metadata": {},
   "source": [
    "*Enhancing Data Predictions through Self-Consistency*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887833c-d74f-46d9-b91a-45a6d4a29015",
   "metadata": {},
   "source": [
    "Additionally, \\citet{cini2023scalable} assume that the input data is originally complete, which is equivalent to interpreting the data as a homogeneous graph from the beginning. Furthermore, \\citet{chen2016learning, xie2020istd} proposed a general model that treats input data as a heterogeneous graph, assuming a lack of supported sensing data. It might be efficient to handle data with a heterogeneous structure in each snapshot. The real dataset frequently exhibit a homogeneous graph, and the introduction of missing values merely transforms it into a heterogeneous graph, implying that the structures of each snapshot remain consistent. In our study, our goal is to effectively manage learning data while maintaining the structures in every snapshot, even when confronted with missing values.\n",
    "    \n",
    "- 논문 목표는 미싱 값 있어도 스냅샷 구조 유지하면서 데이터 학습하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee347ca9-fce5-4b7e-9e42-dece2d1c0560",
   "metadata": {},
   "source": [
    "Various approaches have been attempted in the proposal of methods related to spatio temporal data, aiming to transform irregular patterns into regular ones. Most attempts involved the application of simple handling methods such as linear interpolation. If there is a way to estimate the optimal value other than the interpolation method, it could lead to more accurate predictions and, consequently, more effective results compared to the existing approaches used for spatio temporal data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce843303-b540-42ac-a62d-e3ec3fde00cd",
   "metadata": {},
   "source": [
    "In this paper, we propose an approach that leverages the normal trend of data after handling missing values, utilizing the self-consistency property to enhance the accuracy of data predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c262afd-5fbc-4703-ab1e-2e042a6b41d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa95431-7eb6-49e5-a008-fcdf65ba807c",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430bce9-748c-408f-a572-dcc2acb8e999",
   "metadata": {},
   "source": [
    "## Self-Consistent Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e32259-6e46-4544-881b-41132808a03d",
   "metadata": {},
   "source": [
    "    To deal with incomplete data, we introduce the concept of \"self-consistency\" which is proposed by \\citet{efron1967two} who originally used it to address censored data. Then, \\citet{hastie1989principal} provided a definition of principal curves as smooth curves that maintain self-consistency across a distribution or dataset. Especially, the term of \"self-consistency\" is presented for regression function estimator by \\citet{flury1996self, lee2007self}. According to \\citet{lee2007self}, we can estimate $\\hat{f}_{obs}$ given underlying function of observed data with this specific self-consistent equation:\n",
    "\n",
    "    $E(\\hat{f}_{com} |x_{obs}, f = \\hat{f}_{obs}) = \\hat{f}_{obs} \\cdots (1)$\n",
    "\n",
    "    $\\hat{f}_{com}$ is an estimate of $f$ via $x_{com}$ which is assumed as complete data and consisted of $\\{ x_{obs}, x_{mis}\\}$ where $x_{obs}$ is observed data and $x_{mis}$ is missing value which is not available. Additionally, \\citet{lee2007self} obtained the \"optimal\" estimate $\\hat{f}_{com}$ for their regression function $f$, facilitating the derivation of their \"best\" incomplete data estimator $\\hat{f}_{obs}$ using the corresponding complete data procedure. Given the independence of this equation from estimation, it suggests potential applicability to our dataset assuming the presence of missing values. Under this condition, we extend the self-consistent equation with following one:\n",
    "\n",
    "    $E ( \\hat{s}_{t,com} | \\{ f \\{ n \\} : n \\in O \\}, \\{ s_t \\} = \\{ \\hat{s}_{t, obs} \\})= \\hat{s}_{t, obs}, t = 1, 2, \\dots T \\cdots (2)$\n",
    "\n",
    "    Whitin this context, $\\hat{s}_{com}$ represents an estimation of $s_t$ derived from complete data, while $\\hat{s}_{t,obs}$ is an estimation derived from observed data. We utilized $\\{ \\tilde{f} (n): n \\in M\\}$ as missing data $\\{ f(n): n \\in M\\}$ is not available. After calcurating an estimated complete dataset $\\{ \\hat{f} (n)\\} = \\{ f(n) : n \\in O \\} \\cup \\{ \\tilde{f}(n) : n \\in M\\}$, it can be explained as the corresponding decomposition followed:\n",
    "\n",
    "    $\\hat{f}(n) = \\sum^T_{t=1} \\hat{s}_t(n), t=1,2,\\dots , T\\cdots (3)$\n",
    "\n",
    "    The simplest way to obtain $\\hat{f}_{obs}$ is to update $\\{ f^{(i)}(n): n \\in M\\}$ and decompose $\\hat{f}^{(i)}(n) = \\sum^K_{t=1} \\hat{s}^{(i)}_k(n)$ iteratively. Furthermore, $f^{(i)}(n)$ is satisfied the condition of self-consistency if $f^{(i)}(n) = f^{(i+1)}(n)$, and it was varyfied by \\citet{cox1984analysis, flury1996self}. \n",
    "\n",
    "    Note that we define the $i$ as epoch and use linear implication method for part of missing data in our experiment.\n",
    "\n",
    "    \\subsection{Ebayesthresh}\n",
    "    Then we can say that if $F(\\omega)$ can properly estimated and $F_s(\\omega)$ can be properly extracted from $F(\\omega)$, the deterministic term(underlying function) of $x_t$ can be obtained. We employ the empirical Bayes thresholding bscause we would estimate $F_s(\\omega)$ as a periodogram of $x_t$ and extract $F_s(\\omega)$ from $F(\\omega)$ \\cite{johnstone2005ebayesthresh}. We assume throughout that the observations. \n",
    "\n",
    "    $$X_i \\sim N(\\mu_i,1)$$ \n",
    "\n",
    "    Within a Bayesian context, the notion of sparsity is naturally modeled by a suitable prior distribution for the parameters $\\mu_i$. We model the $\\mu_i$ as having independent prior distributions each given by the mixture \n",
    "    $$f_{\\tt{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w\\gamma(\\mu).$$ \n",
    "\n",
    "   Here the function $\\gamma$ is usually chosen as Laplace density with scale parameter $a > 0$  $\\gamma(u)=\\frac{a}{2}e^{-a|u|}.$ The empirical Bayes approach estimates each $\\mu_i$ by its posterior median. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc2ac1-c432-4335-b8b4-7e2c9e51fcb2",
   "metadata": {},
   "source": [
    "## Ebayse Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0b387-3634-4712-8498-971a0210efcf",
   "metadata": {},
   "source": [
    "First, we give information about ${\\cal G} = \\{ V, E, {\\bf f} \\}$, where $| V|$ is the number of nodes, and we denote $ E$ as edges of the graph, which contains a connection of nodes. We consider an adjacency matrix $\\bf{W} \\in \\mathbf{R}^{T \\times T}$ by assuming that the nodes connect as it is a time-series domain and getting graph Laplacian. And then, we get ${\\bf D}$, which is a diagonal degree matrix, and normalize it. It is available to decompose the graph Laplacian ${\\bf \\tilde L}={\\bf V}{\\bf \\Lambda}{\\bf V}^\\top$. Now, we get Graph Fourier transforms of $\\bf f$ and calculate ${\\bf V}^\\top{\\bf f}$. It allows us to obtain a periodogram of it. We want to get $f_{\\tt trimed}$ so we used Empirical Bayes Thresholding by \\citet{johnstone2004needles} to estimate $f_{\\tt threshed}$ as known as step function from $f$ values. We can impute missing values on their index to calculate $f_{\\tt trimed}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb41ed3-6c56-4456-85e6-c2bd66725315",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69576b66-11a7-4d00-9eb2-eea74076be0e",
   "metadata": {},
   "source": [
    " \\begin{table}[ht]\n",
    "\\centering\n",
    "    \\begin{tabular}{lcc}\n",
    "    \\toprule\n",
    "    Dataset & $V$ &  $T$\\\\\n",
    "    \\midrule\n",
    "    $\\tt{FiveVTS}$             & 5    & 200   \\\\\n",
    "    $\\tt{Chickenpox}$          & 20   & 522   \\\\\n",
    "    $\\tt{Pedalme}$             & 15   & 36    \\\\\n",
    "    $\\tt{Wikimath}$            & 1068 & 731   \\\\\n",
    "    $\\tt{Windmillsmall}$       & 11   & 17,472\\\\\n",
    "    $\\tt{MontevideoBus}$       & 675  & 744   \\\\\n",
    "    % $\\tt{FiveVTS}$\\citep{knight2019generalised}               & 5    & 200   \\\\\n",
    "    % $\\tt{Chickenpox}$\\citep{rozemberczki2021chickenpox}       & 20   & 522   \\\\\n",
    "    % $\\tt{Pedalme}$\\citep{rozemberczki2021pytorch}             & 15   & 36    \\\\\n",
    "    % $\\tt{Wikimath}$\\citep{rozemberczki2021pytorch}            & 1068 & 731   \\\\\n",
    "    % $\\tt{Windmillsmall}$\\citep{rozemberczki2021pytorch}       & 11   & 17,472\\\\\n",
    "    % $\\tt{MontevideoBus}$\\citep{rozemberczki2021pytorch}       & 675  & 744   \\\\\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\caption{Information of Spatio Temporal Datasets including time period($T$) and Nodes($V$); $\\tt{FiveVTS}$\\citep{knight2019generalised}, $\\tt{Chickenpox}$\\citep{rozemberczki2021chickenpox}, $\\tt{Pedalme}$, $\\tt{Wikimath}$, $\\tt{Windmillsmall}$, $\\tt{MontevideoBus}$\\citep{rozemberczki2021pytorch}}\n",
    "    \\label{tab:datainfo}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50137b99-b0ac-4f85-bda6-eff966868293",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791c43b-ea03-4282-945a-d25bc422b4b0",
   "metadata": {},
   "source": [
    "## Overview of Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e7708-2a26-4474-a420-0b2109f6007b",
   "metadata": {},
   "source": [
    "    \\begin{algorithm}\n",
    "    \\caption{ITSTGNN algorithm}\n",
    "    \\begin{algorithmic}[1]\n",
    "        \\INPUT Graph ${\\cal G}$\n",
    "        \\ENSURE ddd\n",
    "        \\STATE dd\n",
    "        \\WHILE{d}\n",
    "            \\STATE ss\n",
    "        \\ENDWHILE\n",
    "    \\end{algorithmic}\n",
    "    \\end{algorithm}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12953f1-691c-429f-85bf-edc7112e3652",
   "metadata": {},
   "source": [
    "   When the graph signal ${\\bf f}$ is given on ${\\cal G} = (V, E)$ on spatio temporal data, The detailed steps of our proposed method are summarized as follows:\n",
    "    \\begin{itemize}\n",
    "    \\item First, we get the observed data given random missing data or block missing data for each node on the graph signal. We construct the complete data using interpolation methods such as linear, nearest, etc.\n",
    "\n",
    "    \\item We define the (normalized) Graph Laplacian as $${\\bf L}={\\bf D}^{-1/2}({\\bf D}-{\\bf W}){\\bf D}^{-1/2}={\\bf I}-\\widetilde{\\bf W}$$ where ${\\bf D}$ represents the degree matrix and $\\widetilde{\\bf W}={\\bf D}^{-1/2}{\\bf W}{\\bf D}^{-1/2}$. Note whether ${\\bf L}$ satisfies the conditions to be considered as a GSO(Graph Signal Operator)\\cite{djuric2018cooperative}.\n",
    "\n",
    "    \\item We perform the eigenvalue decomposition of the Graph Laplacian ${\\bf L}$ as ${\\bf L}={\\bf V}{\\boldsymbol \\Lambda}{\\bf V}^H$. Obtain the Graph Fourier Transform (GFT) of ${\\bf f}$ by calculating ${\\bf V}^H{\\bf f}$.\n",
    "\n",
    "    \\item We then compute the periodogram of ${\\bf f}$, i.e., $\\hat{\\bf p}:=\\frac{1}{R}\\sum_{r=1}^{R}|\\tilde{\\bf f}_r |^2$, where $R$ represents the number of realizations of the process ${\\bf f}$. To estimate the PSD, we obtain $\\hat{\\bf p}_{tr}$ by applying a thresholding operation to $\\hat{\\bf p}$ with Ebayesthresh.\n",
    "\n",
    "    \\item We reconstruct the original signal  ${\\bf f}$ from the thresholded periodogram $\\hat{\\bf p}_{tr}$ using the inverse GFT, and we denote the reconstructed signal as $\\hat{\\bf f}$.\n",
    "\n",
    "    \\item To get $\\hat{\\bf f}_{com}^{(1)}$, we learn the train data using the TGNN(Temporal Graph Neural Network) based on graph structure and update missing values for self-consistency. After we obtain $\\hat{\\bf f}_{obs}^{1}$ by iteratively updating missing points of $\\hat{\\bf f}_{com}^{(n)}$.\n",
    "\n",
    "    \\item After we obtain $\\hat{\\bf f}_{obs}^{1}$ by iteratively updating missing points of $\\hat{\\bf f}_{com}^{(n)}$. \n",
    "\n",
    "    \\item We now can evaluate the performance with the last $\\hat{\\bf f}_{com}^{(n)}$ by calculating MSE(mean squared error).\n",
    "\n",
    "    $${\\bf MSE} = |{\\bf f}-\\hat{\\bf f}|_2^2$$\n",
    "    \\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493557d-b12d-4f79-8ef5-9575f12f59cc",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488283ee-811b-4faa-9a9c-987227df4230",
   "metadata": {},
   "source": [
    "## Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c2a30-69c8-42dc-a970-87339fa45693",
   "metadata": {},
   "source": [
    "    In this section, we evaluated the performance of our proposed method in different architectures by changing the missing proportion of several datasets. Real-world datasets often include a substantial number of missing values, and as the rate of missing values rises, it becomes progressively challenging for the data to follow trends. Therefore, we aim to conduct those experiments with gradually higher rates of missing values. Furthermore, we introduced incomplete data by choosing missing data randomly and in blocks to simulate real-world scenarios. The experiments were conducted under three parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ee068-8d56-420c-af09-ad68f22d3f20",
   "metadata": {},
   "source": [
    "    \\begin{itemize}\n",
    "\n",
    "        \\item{Baseline}: We conducted with the original observed complete data(Table \\ref{tab:datainfo}).\n",
    "        \\item{Randomly Missing}: The proportion of missing values which were selected completly at random was various and that values in every node.\n",
    "        \\item{Block Missing}: We assumed that some nodes experiences missing values during a specific interval.\n",
    "\n",
    "    \\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d90f8f-93bf-4244-8a0f-381ca6bf555a",
   "metadata": {},
   "source": [
    "## Models Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d9077-8dba-412b-8368-400bad82fccf",
   "metadata": {},
   "source": [
    "    We included nine recurrent graph convolutions temporal graph neural networks methods\\cite{rozemberczki2021pytorch}, which incorporates deep learning and parametric learning approaches for processing spatio temporal signals. We also used GNAR(Generalised Network AutoRegressive) proposed by \\cite{knight2019generalised}. GNAR is known as a Graph Deviation Network based on the AR(Auto Regressive) model, a combination of a learning structure and a Graph Neural Network, and it predicts the new value for using the past one\\citep{knight2019generalised}. That is the reason why the forecasting values of GNAR converge to zero. As a result, we employed ten types of different methods in this paper and present the explanations of each model like Table \\ref{tab:modelexp} on \\textbf{Appendix}. We utilized Mean Square Error (MSE) as the evaluation metric to assess the forecasting accuracy of the datasets. The results are presented as Mean $\\pm$ Standard Deviation (SD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38b628-8a58-47bd-be8a-39cf5c03fbd6",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c93d3-2e36-43df-a5e1-8335284f5b0e",
   "metadata": {},
   "source": [
    "    We carried out our experiments using several datasets having stability, which we can get on PyTorch Geometric temporal from \\citet{rozemberczki2021pytorch} and call as Static Graph Temporal Signal(Table \\ref{tab:datainfo}). Also, the dataset was split into training and testing subsets, allocating 80\\% for training and 20\\% for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951caf52-a302-4644-ac70-5fe4a6ad038b",
   "metadata": {},
   "source": [
    "## Randomly Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43b399-3ecd-424b-85c0-d6bd48e2ff74",
   "metadata": {},
   "source": [
    "    \\begin{ex} \n",
    "        Figure \\ref{fig:exfig1} illustrates the outcomes for the $\\tt{Chickenpox}$ dataset organized based on varying levels of missing data, with the GConvLSTM employed. As the missing data rates increase, both Classic(STGNN) and Proposed models(IT-STGNN) exhibit a tendency for the mean squared error (MSE) to rise. Particularly noteworthy is the comparison between the trendlines of Classic and Proposed: as the rate of missing values increases, the MSE of the Proposed method tends to increase more gradually. In contrast, the Classic model displays a more rapid increase in MSE. This comparison suggests that as the ratio of missing values grows, our proposed methods tend to predict better compared to the Classic models. It becomes evident that as the percentage of missing data becomes higher, our proposed method performs relatively well.\n",
    "    \\end{ex}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4523df-bc7f-4d2a-8239-d931cf73bc5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d496b-824c-434f-b1ec-02d8f52fe8cd",
   "metadata": {},
   "source": [
    "    \\begin{figure}\n",
    "        \\centering\n",
    "        \\includegraphics[width=1\\linewidth]{figure/ex1.png}\n",
    "        \\caption{ata.}\n",
    "        \\label{fig:exfig1}\n",
    "    \\end{figure}\n",
    "\n",
    "    \\begin{ex} \n",
    "        Figure \\ref{fig:exfig2} gives information about an overview of experiment outcomes across five datasets at nine archetectures, showcasing the impact of varying rates of randomly distributed missing values. It is clear that most results has the incremental rise in MSE as the outcome of randomly generated missing values increases. Specifically, Classic(STGNN) methods were hugely on the rise compared to Proposed methods(IT-STGNN).\n",
    "    \\end{ex}\n",
    "\n",
    "    \\begin{figure}\n",
    "        \\centering\n",
    "        \\includegraphics[width=1\\linewidth]{figure/ex2.png}\n",
    "        \\caption{ata.}\n",
    "        \\label{fig:exfig2}\n",
    "    \\end{figure}\n",
    "\n",
    "    \\textbf{MSE ranking}\n",
    "    \\begin{ex} \n",
    "        MSE rankings were established independently of missing value rates, with higher MSE values positioned towards the right(Figure \\ref{fig:exfig3}). Observations across datasets consistently highlighted the proposed methods' lower MSE performance compared to the classic methods. Additionally, across the Windmillsmall dataset, all proposed methods reliably showed lower MSE values than the classic methods\n",
    "    \\end{ex}\n",
    "\n",
    "    \\begin{figure}\n",
    "        \\centering\n",
    "        \\includegraphics[width=1\\linewidth]{figure/ex3.png}\n",
    "        \\caption{ata.}\n",
    "        \\label{fig:exfig3}\n",
    "    \\end{figure}\n",
    "\n",
    "    \\textbf{Ratio of datasets' description}\n",
    "    \n",
    "    \\begin{ex} \n",
    "        Figure \\ref{fig:exfig4} illustrated the ratio($\\frac{T}{V}$) of datasets' information based on Table \\ref{tab:datainfo}($y$-axis) and MSE difference between Proposed methods and Classic methods($x$-axis). According to Figure \\ref{fig:exfig4}, as the propotion($\\frac{T}{V}$) grows, the MSE difference is also going up. It leads to a meaning that our proposed methods would outperform at the specific dataset condition which has much time($T$) data. \n",
    "    \\end{ex}\n",
    "\n",
    "    \\begin{figure}\n",
    "        \\centering\n",
    "        \\includegraphics[width=1\\linewidth]{figure/ex4.png}\n",
    "        \\caption{ata.}\n",
    "        \\label{fig:exfig4}\n",
    "    \\end{figure}\n",
    "\n",
    "    \\subsection{Block missing values}\n",
    "\n",
    "    \\begin{ex} \n",
    "        We highlighted the results when datasets has block missing values(Figure \\ref{fig:exfig5}). There was a MSE difference slightly between Proposed methods and Classic methods respectively. Even thought All of the resules had not dramatic differences, MSE of our proposed methods was lower than Classic one generally. Additionally, it would be valuable research to experiment assuming higher block missing rates in the future.\n",
    "    \\end{ex}\n",
    "\n",
    "    \\begin{figure}\n",
    "        \\centering\n",
    "        \\includegraphics[width=1\\linewidth]{figure/ex5.png}\n",
    "        \\caption{ata.}\n",
    "        \\label{fig:exfig5}\n",
    "    \\end{figure}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5560acb-5cae-4a66-b821-439be2e792b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247961c-0159-4f97-99fe-9d040736cfe8",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050070f-9983-4332-b928-7dedcdd92bdc",
   "metadata": {},
   "source": [
    "    This paper aims at getting an effective way to predict real spatio temporal datasets. First, we introduce IT-STGNN, a novel method to achieve self-consistency by updating estimates to analyze spatio temporal datasets with missing values and Ebayesthresh. Briefly, our proposed method could work better than other classic methods when we aussume that thete is the incomplete spatio temporal dataset. Overall, most experiments indicate that our method outperformed other methods, regardless of whether the data has missing data randomly or in blocks.\n",
    "\n",
    "    % Additionally, it remains for a future study to conceive joint time and graph stationary when we calculate the GSO(Graph Shift operator), especially in large datasets. It is expected a better performance of our method shift when simultaneously considering spatio temporal aspects since we consider only time information when calculating GSO in this paper. In this case, we tested on $\\tt{Pedalme}$ and $\\tt{Wikimath}$ datasets by getting GSO with nodes and time-series of graph signals. All settings are the same as in each dataset's experiments without calculating GSO, and the results are in Table \\ref{tb:gsoone} on \\textbf{Appendix} and Table \\ref{tb:gsotwo} on \\textbf{Appendix}. We calculate the weight matrix when we get GSO on $\\tt{Padalme}$ dataset in Table \\ref{tb:gsotwo} on \\textbf{Appendix}. The performances of methods of incomplete data with random missing values achieve lower MSE(Mean Squared Error) compared to other methods. Specifically, GConv GRU, LRGCN, EvolveGCNH, and DCRNN show lower MSE values. \n",
    "    % The output with block missing data also records lower MSE than other methods. In this case, the methods that exhibit lower MSE are GLSTM, EvolveGCNO, EvolveGCNH, and DCRNN. Since the $\\tt{Padalme}$ dataset covers a short time range (less than 40 periods), it would perform well if it had more time points. We consider GSO considering the spatio aspect on $\\tt{Wikimath}$ dataset by supposing having missing data at the same time points. We conducted different approaches for each dataset because the $\\tt{Wikimath}$ dataset has a large number of time points, requiring a more powerful CPU with ample memory. When comparing the performance using Table \\ref{tb:gsotwo} on \\textbf{Appendix}, it shows that considering joint time and graph stationary works better, except for EvolveGCNH. \n",
    "\n",
    "    Lastly, we only used static graph temporal signals, so we expect to explore the use of dynamic graph temporal signals in future research. \n",
    "\n",
    "    In conclusion, the IT-TGNN can successfully predict spatial and temporal features and has no limitations on the extension forecasting method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094a879-5e72-471d-97bc-d767e577ab48",
   "metadata": {},
   "source": [
    "# appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ad505-d19a-4f72-be77-7bf191b01f4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\\section{Classic TGNN}\n",
    "\\begin{table}[ht]\n",
    "  \\centering\n",
    "  \\begin{tabular}{p{4.2cm}|p{4.5cm}|p{7cm}}\n",
    "     \\toprule\n",
    "    \\textbf{Model} & \\textbf{Full Name} & \\textbf{Explanation} \\\\\n",
    "    \\midrule\n",
    "    GConvGRU \\newline \\citep{seo2018structured} & Chebyshev Graph Convolutional Gated Recurrent Unit Cell & It combines the Gated Recurrent Unit (GRU) and Chebyshev Graph Convolutional Network to capture temporal dependencies in graph-structured data effectively. \\\\\n",
    "    GConvLSTM \\newline \\citep{seo2018structured} & Chebyshev Graph Convolutional Long Short Term Memory Cell & It integrates graph convolutions and Long Short Term Memory (LSTM) cells to process graph-structured sequences, effectively capturing node interactions and temporal dependencies. \\\\\n",
    "    GCLSTM \\newline \\citep{chen2022gc} & Graph Convolution Embedded LSTM for Dynamic Link Prediction & A model that combines GCNs and LSTM cells for dynamic link prediction in changing graphs and captures both graph structure and temporal dependencies effectively. \\\\\n",
    "    LRGCN \\newline \\citep{seo2018structured} & Long Short-Term Memory R-GCN & It takes node correlation within a graph snapshot as intra-time relation and interprets temporal dependency between adjacent graph snapshots as inter-time relations. \\\\\n",
    "    DyGrEncoder \\newline \\citep{9073186} & Dynamic Graph Auto-Encoder & It constructs embedding Graph Neural Network (GNN) to LSTM. \\\\\n",
    "    EvolveGCNH \\newline \\citep{pareja2020evolvegcn} & Evolving Graph Convolutional Hidden Layer & A modification of the GCN model that incorporates temporal information without relying on node embeddings. In EvolveGCNH, the GCN weights are treated as hidden states within the recurrent architecture. However, in EvolveGCNO (Evolving Graph Convolutional without Hidden Layer)\\citep{pareja2020evolvegcn}, these weights are used as input or output components directly, without being treated as hidden states. \\\\\n",
    "    TGCN \\newline \\cite{zhao2019t} & Temporal graph convolutional network for traffic prediction & It combines GCN and Gated Recurrent unit. \\\\\n",
    "    DCRNN \\newline \\cite{atwood2016diffusion} & Diffusion Convolutional Recurrent Neural Network & In the traffic flow, it considers both spatial and temporal dependency. \\\\\n",
    "    \\bottomrule\n",
    "  \\end{tabular}\n",
    "  \\caption{This is the explanation of Models that are used in this paper}\n",
    "  \\label{tab:modelexp}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ecd96-6a52-4e06-9fd5-111c4b0fea99",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a48743-a980-494c-8052-d51c4839514b",
   "metadata": {},
   "source": [
    "## Conditions we set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d9d26-32d6-4814-b1a3-294d8edb468e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0064a41-1844-4f1f-885a-d2b42cecd919",
   "metadata": {},
   "source": [
    "% \\begin{table*}\n",
    "% \\vspace{-2.6mm}\n",
    "% \\centering\n",
    "% \\small\n",
    "% \\begin{tabular}{@{}clccccc@{}}  \n",
    "% \\toprule \n",
    "% & & \\multirow{2}{*}{\\textbf{Baseline}} & \\multicolumn{2}{c}{\\textbf{Random}} & \\multicolumn{2}{c}{\\textbf{Block}} \\\\ \n",
    "%                   &&             & Classic        &      Proposed         &  Classic & Proposed\\\\ \\midrule\n",
    "%   \\multirow{11}{*}{ \\makecell{ $\\tt{FiveVTS}$ \\\\ \\textbf{Random(70\\%)} \\\\ \\textbf{Block(12.5\\%)} } }        \n",
    "%  & GConvGRU         & 0.732$\\pm$0.005 & 1.858$\\pm$0.139 & \\textbf{1.180$\\pm$0.060} & 1.210$\\pm$0.039 & \\textbf{1.165$\\pm$0.043}  \\\\\n",
    "%  & GConvLSTM        & 1.131$\\pm$0.041 & 1.472$\\pm$0.125 & \\textbf{1.287$\\pm$0.075} & 1.172$\\pm$0.055 & \\textbf{1.140$\\pm$0.038}  \\\\ \n",
    "%  & GCLSTM           & 0.023$\\pm$0.023 & 1.245$\\pm$0.033 & \\textbf{1.228$\\pm$0.034} & 1.244$\\pm$0.033 & \\textbf{1.219$\\pm$0.025}  \\\\\n",
    "%  & LRGCN            & 0.024$\\pm$0.024 & 1.261$\\pm$0.047 & \\textbf{1.244$\\pm$0.041} & 1.251$\\pm$0.037 & \\textbf{1.220$\\pm$0.020}  \\\\\n",
    "%  & DyGrEncoder      & 1.114$\\pm$0.037 & 1.548$\\pm$0.158 & \\textbf{1.252$\\pm$0.060} & 1.173$\\pm$0.037 & \\textbf{1.124$\\pm$0.035}  \\\\ \n",
    "%  & EvolveGCNH       & 1.175$\\pm$0.068 & 1.228$\\pm$0.064 & \\textbf{1.188$\\pm$0.049} & 1.197$\\pm$0.076 & \\textbf{1.181$\\pm$0.055}  \\\\\n",
    "%  & EvolveGCNO       & 1.168$\\pm$0.065 & 1.198$\\pm$0.045 & \\textbf{1.162$\\pm$0.052} & 1.176$\\pm$0.056 & \\textbf{1.162$\\pm$0.040}  \\\\ \n",
    "%  & TGCN             & 1.085$\\pm$0.016 & 1.184$\\pm$0.057 & \\textbf{1.110$\\pm$0.037} & 1.107$\\pm$0.020 & \\textbf{1.090$\\pm$0.015}  \\\\\n",
    "%  & DCRNN            & 0.041$\\pm$0.041 & 1.271$\\pm$0.066 & \\textbf{1.247$\\pm$0.044} & 1.260$\\pm$0.051 & \\textbf{1.232$\\pm$0.033}  \\\\  \n",
    "%  & GNAR             & 1.407       & \\multicolumn{2}{c}{1.407} &\\multicolumn{2}{c}{1.407}   \\\\ \\midrule\n",
    "% \\multirow{11}{*}{ \\makecell{ $\\tt{Chickenpox}$\\\\\\textbf{Random(80\\%)}\\\\\\textbf{Block(28.8\\%)}}} \n",
    "%  & GConvGRU         & 0.752$\\pm$0.013 & 2.529$\\pm$0.292 & \\textbf{1.586$\\pm$0.199} & 0.828$\\pm$0.022 & \\textbf{0.807$\\pm$0.016}  \\\\\n",
    "%  & GConvLSTM        & 0.959$\\pm$0.088 & 2.522$\\pm$0.111 & \\textbf{1.433$\\pm$0.080} & \\textbf{0.900$\\pm$0.049} & 0.911$\\pm$0.069  \\\\ \n",
    "%  & GCLSTM           & 0.885$\\pm$0.051 & 2.172$\\pm$0.186 & \\textbf{1.371$\\pm$0.072} & 0.890$\\pm$0.033 & \\textbf{0.883$\\pm$0.045}  \\\\\n",
    "%  & LRGCN            & 0.868$\\pm$0.047 & 1.632$\\pm$0.156 & \\textbf{1.334$\\pm$0.071} & 0.911$\\pm$0.047 & \\textbf{0.888$\\pm$0.035}  \\\\\n",
    "%  & DyGrEncoder      & 0.906$\\pm$0.051 & 2.127$\\pm$0.240 & \\textbf{1.399$\\pm$0.063} & 0.912$\\pm$0.043 & \\textbf{0.899$\\pm$0.035}  \\\\ \n",
    "%  & EvolveGCNH       & 1.000$\\pm$0.020 & 1.203$\\pm$0.061 & \\textbf{1.140$\\pm$0.042} & 1.027$\\pm$0.023 & \\textbf{1.007$\\pm$0.021}  \\\\\n",
    "%  & EvolveGCNO       & 0.986$\\pm$0.018 & 1.234$\\pm$0.096 & \\textbf{1.161$\\pm$0.054} & 1.028$\\pm$0.016 & \\textbf{1.002$\\pm$0.015}  \\\\ \n",
    "%  & TGCN             & 1.090$\\pm$0.042 & 1.466$\\pm$0.064 & \\textbf{1.183$\\pm$0.028} & 1.082$\\pm$0.028 & \\textbf{1.065$\\pm$0.031}  \\\\\n",
    "%  & DCRNN            & 0.727$\\pm$0.009 & 2.287$\\pm$0.074 & \\textbf{1.467$\\pm$0.076} & 0.812$\\pm$0.006 & \\textbf{0.740$\\pm$0.007}  \\\\  \n",
    "%  & GNAR             & 1.427       & \\multicolumn{2}{c}{1.427} &\\multicolumn{2}{c}{1.427}   \\\\ \\midrule\n",
    "% \\multirow{11}{*}{ \\makecell{ $\\tt{Pedalme}$\\\\\\textbf{Random(60\\%)}\\\\\\textbf{Block(28.6\\%)}} }\n",
    "%  & GConvGRU         & 1.233$\\pm$0.107 & 1.851$\\pm$0.254 & \\textbf{1.625$\\pm$0.324} & \\textbf{1.270$\\pm$0.114} & 1.289$\\pm$0.115  \\\\\n",
    "%  & GConvLSTM        & 1.214$\\pm$0.055 & 1.274$\\pm$0.078 & \\textbf{1.248$\\pm$0.045} & 1.237$\\pm$0.046 & \\textbf{1.222$\\pm$0.039}  \\\\ \n",
    "%  & GCLSTM           & 1.181$\\pm$0.040 & 1.365$\\pm$0.064 & \\textbf{1.259$\\pm$0.042} & 1.248$\\pm$0.019 & \\textbf{1.195$\\pm$0.029}  \\\\\n",
    "%  & LRGCN            & 1.191$\\pm$0.054 & 1.462$\\pm$0.084 & \\textbf{1.286$\\pm$0.033} & 1.263$\\pm$0.033 & \\textbf{1.165$\\pm$0.035}  \\\\\n",
    "%  & DyGrEncoder      & 1.190$\\pm$0.047 & 1.513$\\pm$0.083 & \\textbf{1.285$\\pm$0.051} & 1.269$\\pm$0.066 & \\textbf{1.165$\\pm$0.032}  \\\\ \n",
    "%  & EvolveGCNH       & 1.213$\\pm$0.057 & 1.284$\\pm$0.066 & \\textbf{1.262$\\pm$0.091} & 1.265$\\pm$0.072 & \\textbf{1.222$\\pm$0.040}  \\\\\n",
    "%  & EvolveGCNO       & 1.223$\\pm$0.051 & 1.292$\\pm$0.075 & \\textbf{1.267$\\pm$0.067} & 1.246$\\pm$0.035 & \\textbf{1.245$\\pm$0.045}  \\\\ \n",
    "%  & TGCN             & 1.307$\\pm$0.075 & 1.301$\\pm$0.090 & \\textbf{1.260$\\pm$0.072} & \\textbf{1.232$\\pm$0.069} & 1.262$\\pm$0.066  \\\\\n",
    "%  & DCRNN            & 1.131$\\pm$0.015 & 1.509$\\pm$0.068 & \\textbf{1.303$\\pm$0.078} & 1.304$\\pm$0.021 & \\textbf{1.150$\\pm$0.014}  \\\\ \n",
    "%  & GNAR             & 1.303       & \\multicolumn{2}{c}{1.303} &\\multicolumn{2}{c}{1.303}   \\\\ \\midrule\n",
    "% \\multirow{11}{*}{ \\makecell{ $\\tt{Wikimath}$\\\\\\textbf{Random(80\\%)}\\\\\\textbf{Block(12\\%)}}} \n",
    "%  & GConvGRU         & 0.931$\\pm$0.002 & 0.932$\\pm$0.043 & \\textbf{0.687$\\pm$0.021} & 0.531$\\pm$0.002 & \\textbf{0.523$\\pm$0.002}  \\\\\n",
    "%  & GConvLSTM        & 0.960$\\pm$0.011 & 1.423$\\pm$0.121 & \\textbf{0.920$\\pm$0.069} & 0.660$\\pm$0.034 & \\textbf{0.627$\\pm$0.014}  \\\\ \n",
    "%  & GCLSTM           & 0.970$\\pm$0.011 & 1.407$\\pm$0.117 & \\textbf{0.815$\\pm$0.058} & \\textbf{0.638$\\pm$0.013} & 0.640$\\pm$0.019  \\\\\n",
    "%  & LRGCN            & 0.980$\\pm$0.024 & 1.105$\\pm$0.099 & \\textbf{0.769$\\pm$0.045} & 0.624$\\pm$0.024 & \\textbf{0.608$\\pm$0.012}  \\\\\n",
    "%  & DyGrEncoder      & 0.995$\\pm$0.034 & 0.770$\\pm$0.045 & \\textbf{0.606$\\pm$0.017} & \\textbf{0.546$\\pm$0.016} & 0.563$\\pm$0.025  \\\\ \n",
    "%  & EvolveGCNH       & 1.182$\\pm$0.192 & 0.915$\\pm$0.063 & \\textbf{0.877$\\pm$0.045} & \\textbf{0.773$\\pm$0.021} & 0.776$\\pm$0.028  \\\\\n",
    "%  & EvolveGCNO       & 1.157$\\pm$0.182 & 0.863$\\pm$0.038 & \\textbf{0.780$\\pm$0.027} & 0.735$\\pm$0.022 & \\textbf{0.732$\\pm$0.025}  \\\\ \n",
    "%  & TGCN             & 0.983$\\pm$0.006 & 0.827$\\pm$0.030 & \\textbf{0.771$\\pm$0.020} & \\textbf{0.741$\\pm$0.046} & 0.748$\\pm$0.046  \\\\\n",
    "%  & DCRNN            & 0.936$\\pm$0.002 & 0.846$\\pm$0.031 & \\textbf{0.672$\\pm$0.007} & \\textbf{0.578$\\pm$0.005} & 0.583$\\pm$0.006  \\\\  \n",
    "%  & GNAR             & 1.354       & \\multicolumn{2}{c}{1.354} &\\multicolumn{2}{c}{1.354}   \\\\ \\midrule\n",
    "% \\multirow{11}{*}{ \\makecell{ $\\tt{Windmillsmall}$\\\\\\textbf{Random(70\\%)}\\\\\\textbf{Block(12.5\\%)}} } \n",
    "%  & GConvGRU         & 1.003$\\pm$0.004 & 1.662$\\pm$0.073 & \\textbf{1.194$\\pm$0.042} & 1.008$\\pm$0.006 & \\textbf{1.007$\\pm$0.005}\\\\\n",
    "%  & GConvLSTM        & 1.019$\\pm$0.045 & 1.600$\\pm$0.056 & \\textbf{1.142$\\pm$0.021} & \\textbf{0.989$\\pm$0.009} & 0.997$\\pm$0.022  \\\\ \n",
    "%  & GCLSTM           & 0.992$\\pm$0.010 & 1.580$\\pm$0.099 & \\textbf{1.117$\\pm$0.021} & \\textbf{0.985$\\pm$0.002} & \\textbf{0.985$\\pm$0.003}  \\\\\n",
    "%  & LRGCN            & 0.987$\\pm$0.006 & 1.492$\\pm$0.087 & \\textbf{1.110$\\pm$0.012} & \\textbf{0.985$\\pm$0.003} & \\textbf{0.985$\\pm$0.002}  \\\\\n",
    "%  & DyGrEncoder      & 0.988$\\pm$0.008 & 0.985$\\pm$0.002 & \\textbf{0.984$\\pm$0.003} & \\textbf{0.985$\\pm$0.003} & \\textbf{0.985$\\pm$0.005}  \\\\ \n",
    "%  & EvolveGCNH       & 0.986$\\pm$0.002 & 1.330$\\pm$0.137 & \\textbf{1.129$\\pm$0.035} & \\textbf{0.993$\\pm$0.003} & 0.986$\\pm$0.003  \\\\\n",
    "%  & EvolveGCNO       & 0.983$\\pm$0.001 & 1.495$\\pm$0.137 & \\textbf{1.149$\\pm$0.026} & 0.990$\\pm$0.002 & \\textbf{0.983$\\pm$0.002}  \\\\ \n",
    "%  & TGCN             & 0.991$\\pm$0.010 & 1.305$\\pm$0.039 & \\textbf{1.071$\\pm$0.010} & 1.000$\\pm$0.014 & \\textbf{0.989$\\pm$0.008}  \\\\\n",
    "%  & DCRNN            & 0.988$\\pm$0.003 & 1.348$\\pm$0.057 & \\textbf{1.117$\\pm$0.034} & 0.994$\\pm$0.005 & \\textbf{0.983$\\pm$0.002}  \\\\  \n",
    "%  & GNAR             & 1.649       & \\multicolumn{2}{c}{1.649} &\\multicolumn{2}{c}{1.649}   \\\\ \\midrule\n",
    "%  \\multirow{11}{*}{ \\makecell{ $\\tt{MontevideoBus}$\\\\\\textbf{Random(80\\%)}\\\\\\textbf{Block(15\\%)}}} \n",
    "%   & GConvGRU         & 0.931$\\pm$0.002 & 1.516$\\pm$0.040 & \\textbf{1.096$\\pm$0.019} & 0.935$\\pm$0.004 & \\textbf{0.932$\\pm$0.002}  \\\\\n",
    "%  & GConvLSTM        & 0.960$\\pm$0.011 & \\textbf{1.134$\\pm$0.069} & 1.156$\\pm$0.062 & 0.950$\\pm$0.005 & \\textbf{0.949$\\pm$0.008}  \\\\ \n",
    "%  & GCLSTM           & 0.970$\\pm$0.011 & 1.140$\\pm$0.061 & \\textbf{1.032$\\pm$0.028} & \\textbf{0.956$\\pm$0.005} & 0.959$\\pm$0.008  \\\\\n",
    "%  & LRGCN            & 0.980$\\pm$0.024 & 0.989$\\pm$0.029 & \\textbf{0.982$\\pm$0.013} & \\textbf{0.977$\\pm$0.020} & 0.978$\\pm$0.024  \\\\\n",
    "%  & DyGrEncoder      & 0.995$\\pm$0.034 & 1.358$\\pm$0.149 & \\textbf{1.216$\\pm$0.118} & 1.030$\\pm$0.044 & \\textbf{1.005$\\pm$0.046}  \\\\ \n",
    "%  & EvolveGCNH       & 1.182$\\pm$0.192 & 2.158$\\pm$0.545 & \\textbf{1.845$\\pm$0.504} & 1.612$\\pm$0.216 & \\textbf{1.392$\\pm$0.110}  \\\\\n",
    "%  & EvolveGCNO       & 1.157$\\pm$0.182 & \\textbf{2.623$\\pm$0.693} & 2.263$\\pm$0.476 & 1.766$\\pm$0.123 & \\textbf{1.345$\\pm$0.110}  \\\\ \n",
    "%  & TGCN             & 0.983$\\pm$0.006 & 1.218$\\pm$0.086 & \\textbf{1.073$\\pm$0.024} & 0.956$\\pm$0.003 & \\textbf{0.940$\\pm$0.001}  \\\\\n",
    "%  & DCRNN            & 0.936$\\pm$0.002 & 1.225$\\pm$0.073 & \\textbf{1.111$\\pm$0.036} & 0.985$\\pm$0.005 & \\textbf{0.984$\\pm$0.007}  \\\\  \n",
    "%  & GNAR             & 1.062       & \\multicolumn{2}{c}{1.062} &\\multicolumn{2}{c}{1.062}   \\\\\n",
    "% \\bottomrule   \n",
    "% \\end{tabular}\n",
    "% \\caption{The performance comparison with TGNN and IT-TGNN on $\\tt{FiveVTS}$, $\\tt{Chickenpox}$, $\\tt{Pedalme}$, $\\tt{Wikimath}$, $\\tt{Windmillsmall}$, $\\tt{MontevideoBus}$ datasets.}\n",
    "% \\label{tab:results}\n",
    "% \\end{table*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645999b4-7638-4d68-a5c6-51e886278e28",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ca8c7-02da-48f4-b343-9b1befaf2c8c",
   "metadata": {},
   "source": [
    "\\begin{table}[H]\n",
    "\\centering\n",
    "\\small\n",
    "\\begin{tabular}{@{}lcccccc@{}}  \n",
    "\\toprule  \n",
    " & $\\tt{FiveVTS}$ &$\\tt{Chickenpox}$&$\\tt{Pedalme}$&$\\tt{Wikimath}$&$\\tt{Windmillsmall}$&$\\tt{MontevideoBus}$        \\\\ \\midrule\n",
    " \\multicolumn{1}{c}{\\textbf{Max iter.} }               &30&30&30&30&30&30 \\\\  \\midrule\n",
    "\\multicolumn{1}{c}{\\textbf{Epochs} }               &50&50&50&50&50&50 \\\\  \\midrule\n",
    "\\multicolumn{1}{c}{\\textbf{Lags}  }                 &2&4&4&8&8&4 \\\\  \\midrule\n",
    " \\multicolumn{1}{c}{\\textbf{Interpolation}} &linear&linear&linear&linear&linear&linear \\\\  \\midrule\n",
    "\\multicolumn{1}{c}{\\textbf{Filters } }&\\multicolumn{6}{l}{} \\\\  \\midrule\n",
    " GConvGRU              &   12    &     16   &  12     & 12       &  12      &   12      \\\\ \n",
    " GConvLSTM             &   12    &    32    &  2      & 64       &  16      &   12      \\\\ \n",
    " GCLSTM                &   4     &     16   &   4     & 64       &  16      &   12      \\\\\n",
    " LRGCN                 &   4     &     8    &  8      & 32       &  12      &  2        \\\\\n",
    " DyGrEncoder           &  12     &    12    &  12     & 12       &  12      &   12      \\\\ \n",
    " EvolveGCNH            &No need  & No need  & No need & No need  & No need  & No need    \\\\\n",
    " EvolveGCNO            &No need  & No need  & No need & No need  & No need  & No need    \\\\ \n",
    " TGCN                  &   12    &  12      &  12     &  12      &  12      & 8         \\\\\n",
    " DCRNN                 &   2     &   16     &  8      &  12      &  4       & 12        \\\\ \n",
    "\\bottomrule    \n",
    "\\end{tabular}\n",
    "\\caption{The information setting inclusing and number of filters by each dataset and model}\n",
    "\\label{tb:results}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce3cfd-2647-44eb-af73-e7ba0760562e",
   "metadata": {},
   "source": [
    "# Time versus Time and Graph stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60351cc-f65b-42ed-bc89-7cd47d25dcde",
   "metadata": {},
   "source": [
    "## Pedalme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbe6de-aeae-4515-b79a-0e70ac6ab3ef",
   "metadata": {},
   "source": [
    "\\begin{table}[H]\n",
    "\\centering\n",
    "\\small\n",
    "\\begin{threeparttable}\n",
    "  \\label{pedalme_GFT_table}\n",
    "  \\begin{tabular}{lcccccc}\n",
    "  \\toprule\n",
    "   & \\multicolumn{3}{c}{\\textbf{Random(60\\%)}}& \\multicolumn{3}{c}{\\textbf{Block(28.6\\%)}} \\\\\n",
    "                 & Classic            &      Proposed        &  Proposed\\tnote{1}           &  Classic                   & Proposed        & Proposed \\tnote{1}  \\\\ \\midrule\n",
    "    GConvGRU     & 1.851$\\pm$0.254 &          1.625$\\pm$0.324 &  \\textbf{1.410$\\pm$0.208}  & \\textbf{1.270$\\pm$0.114} & 1.289$\\pm$0.115 &  1.391$\\pm$0.151         \\\\\n",
    "    GConvLSTM    & 1.274$\\pm$0.078 & \\textbf{1.248$\\pm$0.045} &  1.313$\\pm$0.205  & 1.237$\\pm$0.046 & \\textbf{1.222$\\pm$0.039} &  1.329$\\pm$0.120         \\\\\n",
    "    GCLSTM       & 1.365$\\pm$0.064 &          1.259$\\pm$0.042 &  \\textbf{1.231$\\pm$0.044}  & 1.248$\\pm$0.019 & 1.195$\\pm$0.029 &  \\textbf{1.182$\\pm$0.045}  \\\\\n",
    "    LRGCN        & 1.462$\\pm$0.084 & \\textbf{1.286$\\pm$0.033} &  1.331$\\pm$0.120  & 1.263$\\pm$0.033 & \\textbf{1.165$\\pm$0.035} &  1.201$\\pm$0.081          \\\\\n",
    "    DyGrEncoder  & 1.513$\\pm$0.083 & \\textbf{1.285$\\pm$0.051} &  1.305$\\pm$0.131  & 1.269$\\pm$0.066 & \\textbf{1.165$\\pm$0.032} &  1.196$\\pm$0.055         \\\\\n",
    "    EvolveGCNO   & 1.284$\\pm$0.066 & 1.262$\\pm$0.091 &  \\textbf{1.248$\\pm$0.072}  & 1.265$\\pm$0.072 & 1.222$\\pm$0.040 &  \\textbf{1.204$\\pm$0.033}  \\\\\n",
    "    EvolveGCNH   & 1.292$\\pm$0.075 &          1.267$\\pm$0.067 &  \\textbf{1.246$\\pm$0.067} & 1.246$\\pm$0.035 & 1.245$\\pm$0.045 &  \\textbf{1.188$\\pm$0.042}  \\\\\n",
    "    TGCN         & 1.301$\\pm$0.090 & \\textbf{1.260$\\pm$0.072} &  1.338$\\pm$0.202  & \\textbf{1.232$\\pm$0.069} & 1.262$\\pm$0.066 &  1.243$\\pm$0.110          \\\\\n",
    "    DCRNN        & 1.509$\\pm$0.068 &          1.303$\\pm$0.078 &  \\textbf{1.208$\\pm$0.079}  & 1.304$\\pm$0.021 & 1.150$\\pm$0.014 &  \\textbf{1.145$\\pm$0.013}  \\\\\\bottomrule\n",
    "\n",
    "  \\end{tabular}\n",
    "  \\begin{tablenotes}\n",
    "    \\item[1] Joint Time and Graph Stationarity, which is considered to be jointly stationary in both the vertex and the time domain\n",
    "  \\end{tablenotes}\n",
    "    \\caption{\n",
    "  The results of the $\\tt{Pedalme}$ dataset with the Graph Shift Operator (GSO) were evaluated considering two scenarios: one considering only time stationarity and the other considering both time and graph stationarity.\n",
    "  }\n",
    "\\end{threeparttable}\n",
    "\\label{tb:gsoone}\n",
    "\\end{table} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159b725-4eb1-4b84-8d24-084969a17fff",
   "metadata": {},
   "source": [
    "### Wikimath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ede7b-e7e8-4851-8776-dbf37ecde920",
   "metadata": {},
   "source": [
    "    \\begin{table}[H]\n",
    "    \\centering\n",
    "    \\small\n",
    "        \\begin{threeparttable}[H]\n",
    "        \\label{wikimath_GFT_table}\n",
    "            \\begin{tabular}{lcccc}\n",
    "                \\toprule\n",
    "                &    \\multicolumn{2}{c}{  \\textbf{Random(80\\%)}  }          & \\multicolumn{2}{c}{ \\textbf{The same missing(51.2\\%)} } \\\\\n",
    "                           & Classic            &      Proposed       &  Classic          & Proposed\\tnote{1}  \\\\\\midrule\n",
    "                GConvGRU     & 0.932$\\pm$0.043 & 0.687$\\pm$0.021 & 0.726$\\pm$0.015  &  \\textbf{0.533$\\pm$0.003}     \\\\\n",
    "                GConvLSTM    & 1.423$\\pm$0.121 & 0.920$\\pm$0.069 & 0.963$\\pm$0.098  &  \\textbf{0.653$\\pm$0.033}    \\\\\n",
    "                GCLSTM       & 1.407$\\pm$0.117 & 0.815$\\pm$0.058 & 0.824$\\pm$0.052  &  \\textbf{0.622$\\pm$0.011}    \\\\\n",
    "                LRGCN        & 1.105$\\pm$0.099 & 0.769$\\pm$0.045 & 0.810$\\pm$0.064  &  \\textbf{0.624$\\pm$0.019}   \\\\\n",
    "                DyGrEncoder  & 0.770$\\pm$0.045 & 0.606$\\pm$0.017 & 0.626$\\pm$0.027  &  \\textbf{0.561$\\pm$0.031}   \\\\\n",
    "                EvolveGCNO   & 0.915$\\pm$0.063 & 0.877$\\pm$0.045 & 0.753$\\pm$0.026  &  \\textbf{0.745$\\pm$0.017}    \\\\\n",
    "                EvolveGCNH   & 0.863$\\pm$0.038 & 0.780$\\pm$0.027 & 0.818$\\pm$0.031  &  0.794$\\pm$0.031    \\\\\n",
    "                TGCN         & 0.827$\\pm$0.030 & 0.771$\\pm$0.020 & 0.782$\\pm$0.030  &  \\textbf{0.750$\\pm$0.039}    \\\\\n",
    "                DCRNN        & 0.846$\\pm$0.031 & 0.672$\\pm$0.007 & 0.665$\\pm$0.015  &  \\textbf{0.592$\\pm$0.005}    \\\\\n",
    "                \\bottomrule\n",
    "            \\end{tabular}\n",
    "        \\begin{tablenotes}\n",
    "        \\item[1] Joint Time and Graph Stationarity, which is considered to be jointly stationary in both the vertex and the time domain\n",
    "        \\end{tablenotes}\n",
    "        \\caption{\n",
    "        The performance of the $\\tt{Wikimath}$ dataset with the Graph Shift Operator (GSO) was compared under two different situations: one that considers only time stationarity and another that includes time and graph stationarity, assuming the same index missing data at the same time points for each node.\n",
    "        }\n",
    "        \\end{threeparttable}\n",
    "    \\label{tb:gsotwo}\n",
    "    \\end{table} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd683d-03ee-4dd5-8681-0669fbfd0618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
