<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.527">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2024-05-16">

<title>ITTGNN_blog - 논문 라이팅</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">ITTGNN_blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/sy_hub/"> 
<span class="menu-text">Main_Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">논문 라이팅</li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">논문 라이팅</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 16, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../1_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Studies</strong></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text"><strong>Research</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Research</strong></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text"><strong>Result</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../3_table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Table</strong></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../3_figure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Figure</strong></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#related-work" id="toc-related-work" class="nav-link" data-scroll-target="#related-work">Related work</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a>
  <ul class="collapse">
  <li><a href="#self-consistent-estimator" id="toc-self-consistent-estimator" class="nav-link" data-scroll-target="#self-consistent-estimator">Self-Consistent Estimator</a></li>
  <li><a href="#ebayse-threshold" id="toc-ebayse-threshold" class="nav-link" data-scroll-target="#ebayse-threshold">Ebayse Threshold</a></li>
  <li><a href="#overview-of-method" id="toc-overview-of-method" class="nav-link" data-scroll-target="#overview-of-method">Overview of Method</a></li>
  </ul></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">Experiments</a>
  <ul class="collapse">
  <li><a href="#conditions" id="toc-conditions" class="nav-link" data-scroll-target="#conditions">Conditions</a></li>
  <li><a href="#models-description" id="toc-models-description" class="nav-link" data-scroll-target="#models-description">Models Description</a></li>
  <li><a href="#datasets" id="toc-datasets" class="nav-link" data-scroll-target="#datasets">Datasets</a></li>
  <li><a href="#randomly-missing-values" id="toc-randomly-missing-values" class="nav-link" data-scroll-target="#randomly-missing-values">Randomly Missing values</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix">appendix</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#conditions-we-set" id="toc-conditions-we-set" class="nav-link" data-scroll-target="#conditions-we-set">Conditions we set</a></li>
  </ul></li>
  <li><a href="#time-versus-time-and-graph-stationary" id="toc-time-versus-time-and-graph-stationary" class="nav-link" data-scroll-target="#time-versus-time-and-graph-stationary">Time versus Time and Graph stationary</a>
  <ul class="collapse">
  <li><a href="#pedalme" id="toc-pedalme" class="nav-link" data-scroll-target="#pedalme">Pedalme</a>
  <ul class="collapse">
  <li><a href="#wikimath" id="toc-wikimath" class="nav-link" data-scroll-target="#wikimath">Wikimath</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level1">
<h1>Abstract</h1>
<hr>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In recent years, the field of the spatio temporal dataset has emerged, enabling the simultaneous consideration of both the time and space dimensions. The examples include consumer demand data, wind turbine records, neuroscience data including brain networks, traffic data like taxi GPS traces, and more.</p>
<ul>
<li>STdataset 가 출현함</li>
</ul>
<p>Classic time-series statistical methods to analyze those kind of data already exist, but they are limited by certain conditions, such as assumptions about the data. Specifically, these classic methods are hard to account for spatio temporal correlations and are not designed to work with spatio temporal data.</p>
<ul>
<li>근데 그건 전통적인 시계열로 분석이 어려움</li>
</ul>
<p>In result, when we analize spatio temporal data to use enough information, it leads to improve accuracy during using appropriate geometric deep learning frameworks.</p>
<ul>
<li>그래서 GDL을 써야함
<ul>
<li>접근하는 방법은 크게 전통적인 시계열방법과 GDL이 있음.</li>
</ul></li>
</ul>
<hr>
<p>However, dealing with spatio temporal datasets often presents a common challenge, which is the frequent occurrence of irregularly observed data. For instance, as highlighted by , traffic sensor data commonly suffers from missing observations due to electronic unit failures, which can significantly impact prediction accuracy.</p>
<ul>
<li>그러나 STdataset은 미싱이 있으면 동작X</li>
</ul>
<p>The difficulty in handling irregular data is that many traditional data analysis procedures were designed for datasets with complete observations .</p>
<ul>
<li>이유1. GDL의 대부분 방법은 fully observed 되었다고 가정함.</li>
</ul>
<p>~Second, when dealing with time-series datasets containing missing data, attempting to learn from such data can lead to challenges as it may result in the failure to capture certain time points.~</p>
<ul>
<li>~이유2. -&gt; 시계열에서 미싱이 있을 경우 분석에 어려움이 있다는 연구가 있음.~</li>
</ul>
<p>That’s why it’s essential to transform incomplete data into complete data before conducting any learning or analysis.</p>
<ul>
<li>그래서 complete data를 만들어야함.</li>
</ul>
<p>Therefore, we set the purpose of this paper that finds closely approciate complete data when we approach the irregularly data.</p>
<ul>
<li>이 논문의 목적은 컴플릿 데이터에 가까운 값을 찾는 것임.</li>
</ul>
<hr>
<p>Table 1: Definitions</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notations</th>
<th style="text-align: center;">Definitions or Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\({\cal G}\)</span></td>
<td style="text-align: center;">Input Graph</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(T\)</span></td>
<td style="text-align: center;">the length of the time interval</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\cal{V}\)</span></td>
<td style="text-align: center;">a set of Verteces</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(V\)</span></td>
<td style="text-align: center;">a set of an index node</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(N\)</span></td>
<td style="text-align: center;">the number of Verteces</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\cal{E}\)</span></td>
<td style="text-align: center;">a set of undirected Edges</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\textbf{y}\)</span></td>
<td style="text-align: center;">a graph signal, a function defined on the vertices of the graph <span class="math inline">\(\cal{G}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\textbf{W}\)</span></td>
<td style="text-align: center;">a weighted adjacency matrix</td>
</tr>
</tbody>
</table>
<p>To describe the geometric structures of data domain, graphs are well known as generic data representation forms, so we interpret data on Graph domain. Table 1 indicates the descriptions of notations we use respectively.</p>
<ul>
<li>Shuman 등이 2013년에 발표한 연구에 의하면, 데이터 도메인의 기하학적 구조를 설명할 때 그래프가 일반적인 데이터 표현 형식으로 잘 알려져 있어 데이터를 그래프로 해석함.</li>
</ul>
<p>To simply understand our method, let’s consider the following simple example. Here is a sample dataset:</p>
<ul>
<li>Graph <span class="math inline">\({\cal G} = (\cup_{t \in {\cal T}} {\cal V}_t, \cup_{t \in {\cal T}} {\cal E}_t, \textbf{W})\)</span> ,<span class="math inline">\({\cal T}:=\{1 \text{ to } 10,000\}\)</span></li>
<li><span class="math inline">\(\cal{V}\)</span> is a set of Verteces. <span class="math inline">\({\cal V} = \{ v_0, v_1 \}\)</span>, <span class="math inline">\(|{\cal V}| = 2\)</span>, <span class="math inline">\(V = \{ 0,1\}\)</span></li>
<li><span class="math inline">\(\cal{E}\)</span> is a set of undirected Edges. <span class="math inline">\({\cal E} =\{ ( 0, 1)\}\)</span></li>
<li>a graph signal <span class="math inline">\(\textbf{y}\)</span>: <span class="math inline">\({\cal V}_t \to \mathbb{R}^2\)</span>
<ul>
<li>node 0 <span class="math inline">\(y = \cos(2t) + \cos(4t) + \cos(8t) + \epsilon\)</span></li>
<li>node 1 <span class="math inline">\(y = \cos(2t) + \cos(4t) + \epsilon\)</span></li>
</ul></li>
<li><span class="math inline">\({\cal Y} = \{ y_{v,t}: t \in {\cal T}, v \in V\}\)</span></li>
<li>Define <span class="math inline">\({\cal Y} = ({\cal O} , {\cal M})\)</span></li>
<li>A missing data <span class="math inline">\({\cal M} = \{ y_{v,t_v}: t_v \in {\cal M}_v, v \in V \}\)</span>
<ul>
<li>missing rate on node 0 = random missing 60%</li>
<li>missing rate on node 1 = random missing 60% + block missing <span class="math inline">\(1600\)</span> to <span class="math inline">\(4000\)</span></li>
</ul></li>
<li>A observed data <span class="math inline">\({\cal O} = \{ y_{v,t_v}: t_v \in {\cal O}_v, v \in V \}\)</span></li>
</ul>
<p>For learning data on example, we used GConvGRU. After updating the graph signal set <span class="math inline">\(\cal{Y}\)</span> 200 epochs, we achieved meaningful outcomes(animation link).</p>
<p>In this paper, we expect to contribute as follows:</p>
<ul>
<li>we can appropriately predict data when we get spatio temporal dataset with higher missing rate.</li>
</ul>
<p>우리는 높은 미싱 비율을 가진 stdata를 만날때마다 적절히 대처 가능</p>
<hr>
</section>
<section id="related-work" class="level1">
<h1>Related work</h1>
<p>When observed data is incomplete data, a general approach was approached to handle this problem by using the underlying complete data. defined expectation-maximization algorithm as an iterative technique while computing the log-likelihood from incomplete data. Furthermore, the term of self-consistency is introduced by who showed the similarity between expectation-maximization algorithm and -means algorithm.</p>
<ul>
<li>불완전한 데이터는 완전한 데이터의 언더라인을 찾는 접근이 일반적임</li>
<li>EM 알고리즘 + self-consistency</li>
</ul>
<p>In terms of the irregular spatio temporal data, it poses a challenge as neural networks are more adept at handling regular data. It is often mentioned as the simple solution such as imputation algorithms or linear predictor.</p>
<ul>
<li>비정형 시공간 데이터는 신경망이 처리하기에 더 어려움</li>
<li>간단한 해결책으로는 대체 또는 선형 예측이 있음</li>
</ul>
<p>Furthermore, to fill missing values, employ linear interpolation, while utilize historical data. All of them tried to convert heterogeneous graph into homogeneous graph which has the same types of nodes and edges, while heterogeneous graphs do not.</p>
<ul>
<li>또한, hetero -&gt; homo graph로 바꾸려는 시도들이 있음</li>
</ul>
<hr>
<p><em>Enhancing Data Predictions through Self-Consistency</em></p>
<p>Additionally, assume that the input data is originally complete, which is equivalent to interpreting the data as a homogeneous graph from the beginning. Furthermore, proposed a general model that treats input data as a heterogeneous graph, assuming a lack of supported sensing data. It might be efficient to handle data with a heterogeneous structure in each snapshot. The real dataset frequently exhibit a homogeneous graph, and the introduction of missing values merely transforms it into a heterogeneous graph, implying that the structures of each snapshot remain consistent. In our study, our goal is to effectively manage learning data while maintaining the structures in every snapshot, even when confronted with missing values.</p>
<ul>
<li>논문 목표는 미싱 값 있어도 스냅샷 구조 유지하면서 데이터 학습하는 것</li>
</ul>
<p>Various approaches have been attempted in the proposal of methods related to spatio temporal data, aiming to transform irregular patterns into regular ones. Most attempts involved the application of simple handling methods such as linear interpolation. If there is a way to estimate the optimal value other than the interpolation method, it could lead to more accurate predictions and, consequently, more effective results compared to the existing approaches used for spatio temporal data.</p>
<p>In this paper, we propose an approach that leverages the normal trend of data after handling missing values, utilizing the self-consistency property to enhance the accuracy of data predictions.</p>
<hr>
</section>
<section id="methodology" class="level1">
<h1>Methodology</h1>
<section id="self-consistent-estimator" class="level2">
<h2 class="anchored" data-anchor-id="self-consistent-estimator">Self-Consistent Estimator</h2>
<pre><code>To deal with incomplete data, we introduce the concept of "self-consistency" which is proposed by \citet{efron1967two} who originally used it to address censored data. Then, \citet{hastie1989principal} provided a definition of principal curves as smooth curves that maintain self-consistency across a distribution or dataset. Especially, the term of "self-consistency" is presented for regression function estimator by \citet{flury1996self, lee2007self}. According to \citet{lee2007self}, we can estimate $\hat{f}_{obs}$ given underlying function of observed data with this specific self-consistent equation:

$E(\hat{f}_{com} |x_{obs}, f = \hat{f}_{obs}) = \hat{f}_{obs} \cdots (1)$

$\hat{f}_{com}$ is an estimate of $f$ via $x_{com}$ which is assumed as complete data and consisted of $\{ x_{obs}, x_{mis}\}$ where $x_{obs}$ is observed data and $x_{mis}$ is missing value which is not available. Additionally, \citet{lee2007self} obtained the "optimal" estimate $\hat{f}_{com}$ for their regression function $f$, facilitating the derivation of their "best" incomplete data estimator $\hat{f}_{obs}$ using the corresponding complete data procedure. Given the independence of this equation from estimation, it suggests potential applicability to our dataset assuming the presence of missing values. Under this condition, we extend the self-consistent equation with following one:

$E ( \hat{s}_{t,com} | \{ f \{ n \} : n \in O \}, \{ s_t \} = \{ \hat{s}_{t, obs} \})= \hat{s}_{t, obs}, t = 1, 2, \dots T \cdots (2)$

Whitin this context, $\hat{s}_{com}$ represents an estimation of $s_t$ derived from complete data, while $\hat{s}_{t,obs}$ is an estimation derived from observed data. We utilized $\{ \tilde{f} (n): n \in M\}$ as missing data $\{ f(n): n \in M\}$ is not available. After calcurating an estimated complete dataset $\{ \hat{f} (n)\} = \{ f(n) : n \in O \} \cup \{ \tilde{f}(n) : n \in M\}$, it can be explained as the corresponding decomposition followed:

$\hat{f}(n) = \sum^T_{t=1} \hat{s}_t(n), t=1,2,\dots , T\cdots (3)$

The simplest way to obtain $\hat{f}_{obs}$ is to update $\{ f^{(i)}(n): n \in M\}$ and decompose $\hat{f}^{(i)}(n) = \sum^K_{t=1} \hat{s}^{(i)}_k(n)$ iteratively. Furthermore, $f^{(i)}(n)$ is satisfied the condition of self-consistency if $f^{(i)}(n) = f^{(i+1)}(n)$, and it was varyfied by \citet{cox1984analysis, flury1996self}. 

Note that we define the $i$ as epoch and use linear implication method for part of missing data in our experiment.

\subsection{Ebayesthresh}
Then we can say that if $F(\omega)$ can properly estimated and $F_s(\omega)$ can be properly extracted from $F(\omega)$, the deterministic term(underlying function) of $x_t$ can be obtained. We employ the empirical Bayes thresholding bscause we would estimate $F_s(\omega)$ as a periodogram of $x_t$ and extract $F_s(\omega)$ from $F(\omega)$ \cite{johnstone2005ebayesthresh}. We assume throughout that the observations. 

$$X_i \sim N(\mu_i,1)$$ 

Within a Bayesian context, the notion of sparsity is naturally modeled by a suitable prior distribution for the parameters $\mu_i$. We model the $\mu_i$ as having independent prior distributions each given by the mixture 
$$f_{\tt{prior}}(\mu)=(1-w)\delta_0(\mu)+w\gamma(\mu).$$ </code></pre>
<p>Here the function <span class="math inline">\(\gamma\)</span> is usually chosen as Laplace density with scale parameter <span class="math inline">\(a &gt; 0\)</span> <span class="math inline">\(\gamma(u)=\frac{a}{2}e^{-a|u|}.\)</span> The empirical Bayes approach estimates each <span class="math inline">\(\mu_i\)</span> by its posterior median.</p>
</section>
<section id="ebayse-threshold" class="level2">
<h2 class="anchored" data-anchor-id="ebayse-threshold">Ebayse Threshold</h2>
<p>First, we give information about <span class="math inline">\({\cal G} = \{ V, E, {\bf f} \}\)</span>, where <span class="math inline">\(| V|\)</span> is the number of nodes, and we denote $ E$ as edges of the graph, which contains a connection of nodes. We consider an adjacency matrix <span class="math inline">\(\bf{W} \in \mathbf{R}^{T \times T}\)</span> by assuming that the nodes connect as it is a time-series domain and getting graph Laplacian. And then, we get <span class="math inline">\({\bf D}\)</span>, which is a diagonal degree matrix, and normalize it. It is available to decompose the graph Laplacian <span class="math inline">\({\bf \tilde L}={\bf V}{\bf \Lambda}{\bf V}^\top\)</span>. Now, we get Graph Fourier transforms of <span class="math inline">\(\bf f\)</span> and calculate <span class="math inline">\({\bf V}^\top{\bf f}\)</span>. It allows us to obtain a periodogram of it. We want to get <span class="math inline">\(f_{\tt trimed}\)</span> so we used Empirical Bayes Thresholding by to estimate <span class="math inline">\(f_{\tt threshed}\)</span> as known as step function from <span class="math inline">\(f\)</span> values. We can impute missing values on their index to calculate <span class="math inline">\(f_{\tt trimed}\)</span>.</p>
<hr>
<hr>
</section>
<section id="overview-of-method" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-method">Overview of Method</h2>
<pre><code>\begin{algorithm}
\caption{ITSTGNN algorithm}
\begin{algorithmic}[1]
    \INPUT Graph ${\cal G}$
    \ENSURE ddd
    \STATE dd
    \WHILE{d}
        \STATE ss
    \ENDWHILE
\end{algorithmic}
\end{algorithm}</code></pre>
When the graph signal <span class="math inline">\({\bf f}\)</span> is given on <span class="math inline">\({\cal G} = (V, E)\)</span> on spatio temporal data, The detailed steps of our proposed method are summarized as follows:
</section>
</section>
<section id="experiments" class="level1">
<h1>Experiments</h1>
<section id="conditions" class="level2">
<h2 class="anchored" data-anchor-id="conditions">Conditions</h2>
<pre><code>In this section, we evaluated the performance of our proposed method in different architectures by changing the missing proportion of several datasets. Real-world datasets often include a substantial number of missing values, and as the rate of missing values rises, it becomes progressively challenging for the data to follow trends. Therefore, we aim to conduct those experiments with gradually higher rates of missing values. Furthermore, we introduced incomplete data by choosing missing data randomly and in blocks to simulate real-world scenarios. The experiments were conducted under three parts:

\begin{itemize}

    \item{Baseline}: We conducted with the original observed complete data(Table \ref{tab:datainfo}).
    \item{Randomly Missing}: The proportion of missing values which were selected completly at random was various and that values in every node.
    \item{Block Missing}: We assumed that some nodes experiences missing values during a specific interval.

\end{itemize}</code></pre>
</section>
<section id="models-description" class="level2">
<h2 class="anchored" data-anchor-id="models-description">Models Description</h2>
<pre><code>We included nine recurrent graph convolutions temporal graph neural networks methods\cite{rozemberczki2021pytorch}, which incorporates deep learning and parametric learning approaches for processing spatio temporal signals. We also used GNAR(Generalised Network AutoRegressive) proposed by \cite{knight2019generalised}. GNAR is known as a Graph Deviation Network based on the AR(Auto Regressive) model, a combination of a learning structure and a Graph Neural Network, and it predicts the new value for using the past one\citep{knight2019generalised}. That is the reason why the forecasting values of GNAR converge to zero. As a result, we employed ten types of different methods in this paper and present the explanations of each model like Table \ref{tab:modelexp} on \textbf{Appendix}. We utilized Mean Square Error (MSE) as the evaluation metric to assess the forecasting accuracy of the datasets. The results are presented as Mean $\pm$ Standard Deviation (SD).</code></pre>
</section>
<section id="datasets" class="level2">
<h2 class="anchored" data-anchor-id="datasets">Datasets</h2>
<pre><code>We carried out our experiments using several datasets having stability, which we can get on PyTorch Geometric temporal from \citet{rozemberczki2021pytorch} and call as Static Graph Temporal Signal(Table \ref{tab:datainfo}). Also, the dataset was split into training and testing subsets, allocating 80\% for training and 20\% for testing purposes.</code></pre>
</section>
<section id="randomly-missing-values" class="level2">
<h2 class="anchored" data-anchor-id="randomly-missing-values">Randomly Missing values</h2>
<pre><code>\begin{ex} 
    Figure \ref{fig:exfig1} illustrates the outcomes for the $\tt{Chickenpox}$ dataset organized based on varying levels of missing data, with the GConvLSTM employed. As the missing data rates increase, both Classic(STGNN) and Proposed models(IT-STGNN) exhibit a tendency for the mean squared error (MSE) to rise. Particularly noteworthy is the comparison between the trendlines of Classic and Proposed: as the rate of missing values increases, the MSE of the Proposed method tends to increase more gradually. In contrast, the Classic model displays a more rapid increase in MSE. This comparison suggests that as the ratio of missing values grows, our proposed methods tend to predict better compared to the Classic models. It becomes evident that as the percentage of missing data becomes higher, our proposed method performs relatively well.
\end{ex}</code></pre>
<hr>
<pre><code>\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/ex1.png}
    \caption{ata.}
    \label{fig:exfig1}
\end{figure}

\begin{ex} 
    Figure \ref{fig:exfig2} gives information about an overview of experiment outcomes across five datasets at nine archetectures, showcasing the impact of varying rates of randomly distributed missing values. It is clear that most results has the incremental rise in MSE as the outcome of randomly generated missing values increases. Specifically, Classic(STGNN) methods were hugely on the rise compared to Proposed methods(IT-STGNN).
\end{ex}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/ex2.png}
    \caption{ata.}
    \label{fig:exfig2}
\end{figure}

\textbf{MSE ranking}
\begin{ex} 
    MSE rankings were established independently of missing value rates, with higher MSE values positioned towards the right(Figure \ref{fig:exfig3}). Observations across datasets consistently highlighted the proposed methods' lower MSE performance compared to the classic methods. Additionally, across the Windmillsmall dataset, all proposed methods reliably showed lower MSE values than the classic methods
\end{ex}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/ex3.png}
    \caption{ata.}
    \label{fig:exfig3}
\end{figure}

\textbf{Ratio of datasets' description}

\begin{ex} 
    Figure \ref{fig:exfig4} illustrated the ratio($\frac{T}{V}$) of datasets' information based on Table \ref{tab:datainfo}($y$-axis) and MSE difference between Proposed methods and Classic methods($x$-axis). According to Figure \ref{fig:exfig4}, as the propotion($\frac{T}{V}$) grows, the MSE difference is also going up. It leads to a meaning that our proposed methods would outperform at the specific dataset condition which has much time($T$) data. 
\end{ex}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/ex4.png}
    \caption{ata.}
    \label{fig:exfig4}
\end{figure}

\subsection{Block missing values}

\begin{ex} 
    We highlighted the results when datasets has block missing values(Figure \ref{fig:exfig5}). There was a MSE difference slightly between Proposed methods and Classic methods respectively. Even thought All of the resules had not dramatic differences, MSE of our proposed methods was lower than Classic one generally. Additionally, it would be valuable research to experiment assuming higher block missing rates in the future.
\end{ex}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/ex5.png}
    \caption{ata.}
    \label{fig:exfig5}
\end{figure}</code></pre>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<pre><code>This paper aims at getting an effective way to predict real spatio temporal datasets. First, we introduce IT-STGNN, a novel method to achieve self-consistency by updating estimates to analyze spatio temporal datasets with missing values and Ebayesthresh. Briefly, our proposed method could work better than other classic methods when we aussume that thete is the incomplete spatio temporal dataset. Overall, most experiments indicate that our method outperformed other methods, regardless of whether the data has missing data randomly or in blocks.

% Additionally, it remains for a future study to conceive joint time and graph stationary when we calculate the GSO(Graph Shift operator), especially in large datasets. It is expected a better performance of our method shift when simultaneously considering spatio temporal aspects since we consider only time information when calculating GSO in this paper. In this case, we tested on $\tt{Pedalme}$ and $\tt{Wikimath}$ datasets by getting GSO with nodes and time-series of graph signals. All settings are the same as in each dataset's experiments without calculating GSO, and the results are in Table \ref{tb:gsoone} on \textbf{Appendix} and Table \ref{tb:gsotwo} on \textbf{Appendix}. We calculate the weight matrix when we get GSO on $\tt{Padalme}$ dataset in Table \ref{tb:gsotwo} on \textbf{Appendix}. The performances of methods of incomplete data with random missing values achieve lower MSE(Mean Squared Error) compared to other methods. Specifically, GConv GRU, LRGCN, EvolveGCNH, and DCRNN show lower MSE values. 
% The output with block missing data also records lower MSE than other methods. In this case, the methods that exhibit lower MSE are GLSTM, EvolveGCNO, EvolveGCNH, and DCRNN. Since the $\tt{Padalme}$ dataset covers a short time range (less than 40 periods), it would perform well if it had more time points. We consider GSO considering the spatio aspect on $\tt{Wikimath}$ dataset by supposing having missing data at the same time points. We conducted different approaches for each dataset because the $\tt{Wikimath}$ dataset has a large number of time points, requiring a more powerful CPU with ample memory. When comparing the performance using Table \ref{tb:gsotwo} on \textbf{Appendix}, it shows that considering joint time and graph stationary works better, except for EvolveGCNH. 

Lastly, we only used static graph temporal signals, so we expect to explore the use of dynamic graph temporal signals in future research. 

In conclusion, the IT-TGNN can successfully predict spatial and temporal features and has no limitations on the extension forecasting method.</code></pre>
</section>
<section id="appendix" class="level1">
<h1>appendix</h1>

</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="conditions-we-set" class="level2">
<h2 class="anchored" data-anchor-id="conditions-we-set">Conditions we set</h2>
<hr>
% \begin{table*} % % % %
<p>\end{table}</p>
</section>
</section>
<section id="time-versus-time-and-graph-stationary" class="level1">
<h1>Time versus Time and Graph stationary</h1>
<section id="pedalme" class="level2">
<h2 class="anchored" data-anchor-id="pedalme">Pedalme</h2>
<section id="wikimath" class="level3">
<h3 class="anchored" data-anchor-id="wikimath">Wikimath</h3>
<pre><code>\begin{table}[H]
\centering
\small
    \begin{threeparttable}[H]
    \label{wikimath_GFT_table}
        \begin{tabular}{lcccc}
            \toprule
            &amp;    \multicolumn{2}{c}{  \textbf{Random(80\%)}  }          &amp; \multicolumn{2}{c}{ \textbf{The same missing(51.2\%)} } \\
                       &amp; Classic            &amp;      Proposed       &amp;  Classic          &amp; Proposed\tnote{1}  \\\midrule
            GConvGRU     &amp; 0.932$\pm$0.043 &amp; 0.687$\pm$0.021 &amp; 0.726$\pm$0.015  &amp;  \textbf{0.533$\pm$0.003}     \\
            GConvLSTM    &amp; 1.423$\pm$0.121 &amp; 0.920$\pm$0.069 &amp; 0.963$\pm$0.098  &amp;  \textbf{0.653$\pm$0.033}    \\
            GCLSTM       &amp; 1.407$\pm$0.117 &amp; 0.815$\pm$0.058 &amp; 0.824$\pm$0.052  &amp;  \textbf{0.622$\pm$0.011}    \\
            LRGCN        &amp; 1.105$\pm$0.099 &amp; 0.769$\pm$0.045 &amp; 0.810$\pm$0.064  &amp;  \textbf{0.624$\pm$0.019}   \\
            DyGrEncoder  &amp; 0.770$\pm$0.045 &amp; 0.606$\pm$0.017 &amp; 0.626$\pm$0.027  &amp;  \textbf{0.561$\pm$0.031}   \\
            EvolveGCNO   &amp; 0.915$\pm$0.063 &amp; 0.877$\pm$0.045 &amp; 0.753$\pm$0.026  &amp;  \textbf{0.745$\pm$0.017}    \\
            EvolveGCNH   &amp; 0.863$\pm$0.038 &amp; 0.780$\pm$0.027 &amp; 0.818$\pm$0.031  &amp;  0.794$\pm$0.031    \\
            TGCN         &amp; 0.827$\pm$0.030 &amp; 0.771$\pm$0.020 &amp; 0.782$\pm$0.030  &amp;  \textbf{0.750$\pm$0.039}    \\
            DCRNN        &amp; 0.846$\pm$0.031 &amp; 0.672$\pm$0.007 &amp; 0.665$\pm$0.015  &amp;  \textbf{0.592$\pm$0.005}    \\
            \bottomrule
        \end{tabular}
    \begin{tablenotes}
    \item[1] Joint Time and Graph Stationarity, which is considered to be jointly stationary in both the vertex and the time domain
    \end{tablenotes}
    \caption{
    The performance of the $\tt{Wikimath}$ dataset with the Graph Shift Operator (GSO) was compared under two different situations: one that considers only time stationarity and another that includes time and graph stationarity, assuming the same index missing data at the same time points for each node.
    }
    \end{threeparttable}
\label{tb:gsotwo}
\end{table} </code></pre>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>